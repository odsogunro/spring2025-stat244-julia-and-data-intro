{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Spring 20205 - STAT244 - Julia and Data\"\n",
    "subtitle: \"DataFrames, ... \"\n",
    "author: Olorundamilola 'Dami' Kazeem\n",
    "date: today\n",
    "format:\n",
    "  pdf:\n",
    "    documentclass: article\n",
    "    margin-left: 30mm\n",
    "    margin-right: 30mm\n",
    "    toc: false\n",
    "  html:\n",
    "    theme: cosmo\n",
    "    css: ../styles.css\n",
    "    toc: false\n",
    "    code-copy: true\n",
    "    code-block-background: true\n",
    "execute:\n",
    "  freeze: auto\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spring 2025 - STAT244 - Julia and Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents ... Presentation Outline\n",
    "\n",
    "1. Introduction\n",
    "\n",
    "2. Julia and the Data Ecosystem\n",
    "\n",
    "3. Introduction to [DataFrames.jl](https://dataframes.juliadata.org/stable/)\n",
    "    1. What is a DataFrame?\n",
    "    2. Key Features of DataFrames.jl\n",
    "    3. Basic Operations\n",
    "    4. Mock(or Real) World Example\n",
    "\n",
    "4. Introduction to [DataFramesMeta.jl](https://juliadata.org/DataFramesMeta.jl/stable/)\n",
    "    1. What is DataFramesMeta.jl?\n",
    "    2. Key Features of DataFramesMeta.jl\n",
    "    3. Basic Operations\n",
    "    4. Mock (or Real) World Example\n",
    "\n",
    "5. Introduction to [Arrow.jl](https://arrow.apache.org/julia/stable/)\n",
    "\n",
    "    1. What is Apache Arrow?\n",
    "    2. Why use Arrow?\n",
    "    3. Mock (or Real) World Example\n",
    "\n",
    "6. Introduction to [Big Data Analysis in Julia](...)\n",
    "\n",
    "    1. Challenges of Big Data\n",
    "    2. Julia’s Approach to Big Data \n",
    "    3. Mention of Distributed Computing via [Distributed.jl](https://docs.julialang.org/en/v1/stdlib/Distributed/)\n",
    "    4. Mention of Out-of-Core Computing via [Dagger.jl](https://juliaparallel.org/Dagger.jl/stable/)\n",
    "\n",
    "7. Questions? Fin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "\n",
    "Pkg.activate(\".\")\n",
    "\n",
    "Pkg.add(\"BenchmarkTools\")\n",
    "\n",
    "Pkg.add(\"DataFrames\")\n",
    "Pkg.add(\"DataFramesMeta\")\n",
    "\n",
    "Pkg.add(\"CSV\")\n",
    "Pkg.add(\"Arrow\")\n",
    "\n",
    "Pkg.add(\"Distributed\")\n",
    "Pkg.add(\"Dagger\")\n",
    "\n",
    "Pkg.add(\"Plots\")\n",
    "Pkg.add(\"GR\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools\n",
    "\n",
    "using DataFrames\n",
    "using DataFramesMeta\n",
    "\n",
    "using CSV\n",
    "using Arrow\n",
    "\n",
    "using Distributed\n",
    "using Dagger\n",
    "\n",
    "using Plots\n",
    "using GR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Introduction](...)\n",
    "\n",
    "What is **[data literacy](https://en.wikipedia.org/wiki/Data_literacy)**?\n",
    "\n",
    "As defined by Wikipedia:\n",
    "\n",
    "- It is the ability to read, understand, create, and communicate **[data](https://en.wikipedia.org/wiki/Data)** as information. \n",
    "\n",
    "- It focuses on the competencies involved in working with data. \n",
    "\n",
    "- It requires certain skills involving reading and understanding data.\n",
    "\n",
    "What is [data](https://en.wikipedia.org/wiki/Data)?\n",
    "\n",
    "As defined by Wikipedia:\n",
    "\n",
    "- A collection of discrete or continuous values that convey information, describing the quantity, quality, fact, statistics, other basic units of meaning\n",
    "\n",
    "- A sequence of symbols that may be further interpreted formally; and may be used as variables in a computational process, which may represent abstract ideas or concrete measurements\n",
    "\n",
    "![Data_Types](./img/Data_types_-_en.svg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Julia and the Data Ecosystem v0.0 - Initial Outline\n",
    "\n",
    "**How to interact with your data in the Julia Data **[JuliaData](https://github.com/JuliaData)** ecosystem?** \n",
    "\n",
    "_**NOTE:**_ There's a lot of ground to cover when it comes to data! Below are just of few directions:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Data Analysis \n",
    "Julia’s ecosystem includes mature packages like **[DataFrames.jl](https://dataframes.juliadata.org/stable/)** and **[Query.jl](https://www.queryverse.org/Query.jl/stable/)**, which provide robust capabilities for data manipulation, transformation, and exploratory analysis. These tools allow users to work with large datasets in a way that is both intuitive and high-performance.\n",
    "\n",
    "### Data Processing\n",
    "For tasks involving data ingestion and transformation, Julia offers packages such as **[CSV.jl](https://csv.juliadata.org/stable/)** for fast, efficient reading and writing of CSV files, as well as other tools for parsing and processing different data formats. Its design emphasizes speed and efficiency, making it well-suited for handling big data and real-time processing scenarios.\n",
    "\n",
    "### Data Science\n",
    "Julia's performance and syntax make it a strong candidate for data science applications. The language supports statistical modeling, machine learning, and scientific computing through libraries like **[MLJ.jl](https://juliaai.github.io/MLJ.jl/stable/)** for machine learning and **[Flux.jl](https://fluxml.ai/Flux.jl/stable/)** for deep learning. This makes it possible to build and deploy predictive models and complex analytical pipelines with ease.\n",
    "\n",
    "### Databases\n",
    "Interacting with databases in Julia via **[Julia Database Interfaces](https://juliadatabases.org)** is streamlined by packages like **[LibPQ.jl](https://github.com/JuliaDatabases/LibPQ.jl)** for PostgreSQL, **[SQLite.jl](https://juliadatabases.org/SQLite.jl/stable/)** for lightweight database management, and **[ODBC.jl](https://odbc.juliadatabases.org/dev/)** for a range of other SQL databases. These libraries enable efficient data retrieval, storage, and manipulation directly within the Julia environment.\n",
    "\n",
    "### Data Miscellaneous\n",
    "Beyond the core areas, Julia excels in other data-related domains such as:\n",
    "- **Data Cleaning and Wrangling:** Leveraging its high-level syntax and powerful libraries to prepare data for analysis, such as [Cleaner.jl](https://theronione.github.io/Cleaner.jl/stable/) a toolbox of simple solutions for common data cleaning problems.\n",
    "- **Data Visualization:** Utilizing packages like **[Plots.jl](https://docs.juliaplots.org/stable/)**, **[Makie.jl](https://docs.makie.org/v0.22/)**, and **[Gadfly.jl](https://gadflyjl.org/stable/)** for creating both static and interactive visualizations.\n",
    "- **Parallel and Distributed Computing:** Julia’s native support for parallelism makes it a great choice for scaling data processing and analysis tasks across multiple cores or nodes.\n",
    "\n",
    "Overall, Julia’s growing ecosystem and its blend of high-level expressiveness with low-level performance make it a versatile language for everything from exploratory data analysis to building large-scale data processing and machine learning pipelines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction to [DataFrames.jl](https://dataframes.juliadata.org/stable/)\n",
    "\n",
    "\n",
    "DataFrames.jl provides a set of tools for working with tabular data in Julia. Its design and functionality are similar to those of `pandas` (in Python) and `data.frame`, `data.table` and `dplyr` (in R), making it a great general purpose data science tool.\n",
    "\n",
    "To work with tabular datasets and perform common data manipulations\n",
    "\n",
    "1. What is a DataFrame?\n",
    "2. Key Features of DataFrames.jl\n",
    "3. Basic Operations\n",
    "4. Mock( or Real) World Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dataframe\n",
    "\n",
    "df = DataFrame()\n",
    "println(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. What is a DataFrame?\n",
    "\n",
    "\n",
    "- **Definition:** \n",
    "    - A DataFrame is a tabular data structure, similar to a spreadsheet or SQL table, where data is organized in rows (observations) and columns (heterogeneous types).\n",
    "\n",
    "- **Purpose:** \n",
    "    - Used for storing, manipulating, and analyzing structured data.\n",
    "\n",
    "- **Analogy:** \n",
    "    - Think of it as a table in Excel or a table in a database. \n",
    "    - Like a spreadsheet or SQL table, but optimized for programmatic workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple DataFrame\n",
    "\n",
    "df0 = DataFrame(\n",
    "    Name = [\"Alice\", \"Bob\", \"Charlie\"],\n",
    "    Age = [25, 30, 35],\n",
    "    Salary = [50_000, 75_000, 90_000]\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(df0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(df0.Salary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**\n",
    "\n",
    "- DataFrames.jl's guiding principles can be found [here](https://bkamins.github.io/julialang/2021/05/14/nrow.html); however, two core ones are listed below:\n",
    "\n",
    "    - Stay consistent with Julia' `Base` module functions.\n",
    "    - Minimize the number of function `DataFrames.jl` provides.\n",
    "\n",
    "- Columns can have different data types (e.g., String, Int64).\n",
    "\n",
    "- Rows represent individual observations, and columns represent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Key Features of DataFrame.jl\n",
    "\n",
    "- **Columnar Storage:** Efficient for column-based operations. Optimized for column-wise operations (e.g., `mean(df.Salary)`).\n",
    "\n",
    "- **Missing Data Handling:** Built-in support for Missing type  (e.g., `dropmissing(df)`).\n",
    "\n",
    "- **Integration:** Works seamlessly with other Julia packages (e.g., CSV.jl, Arrow.jl, Plots.jl).\n",
    "\n",
    "- **Performance:** Optimized for fast data manipulation.\n",
    "\n",
    "- **Flexibility:** Built for speed (no copies, vectorized operations) Supports a wide range of data types and operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing data\n",
    "\n",
    "df = DataFrame(Name = [\"Alice\", missing, \"Charlie\"], Age = [25, 30, missing]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing values\n",
    "clean_df = dropmissing(df)  \n",
    "println(clean_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE\n",
    "\n",
    "- Missing type allows for explicit handling of incomplete data.\n",
    "\n",
    "- Use `dropmissing(df)` to remove rows with missing values.\n",
    "\n",
    "- Use `dropmissing`, `coalesce`, or `replace!` to handle missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Basic Operations\n",
    "\n",
    "- **Reading and Writing a DataFrame:** To/From vectors, dictionaries, csv files, or databases.\n",
    "\n",
    "- **Accessing Data:** Rows, columns, and individual elements.\n",
    "\n",
    "- **Modifying Data:** Adding, removing, and transforming columns.\n",
    "\n",
    "- **Filtering and Sorting:** Subsetting rows and ordering data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accessing Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with mock data\n",
    "df = DataFrame(\n",
    "    ID = 1:5,\n",
    "    Name = [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eve\"],\n",
    "    Age = rand(20:30, 5),      # Random ages between 20 and 30\n",
    "    Score = round.(rand(5) * 100, digits=2),  # Random scores between 0 and 100\n",
    "    Active = rand(Bool, 5)      # Random boolean values\n",
    ")\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "CSV.write(\"data.csv\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = CSV.read(\"data.csv\", DataFrame)\n",
    "println(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acessing Data by Column Name\n",
    "println(df.Name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Rows: `df[1:3, :]` or use Julia's built-in `filter(:Age => >(25), df)`.\n",
    "\n",
    "- Columns: `df.Name` (copying) or `df[!, :Name]` (non-copying)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing Data by Row Index (and for all Columns)\n",
    "println(df[5, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modifying Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifying in-place (non-copy) DataFrame and Data by Column Name\n",
    "\n",
    "df[!, :Bonus] = df.Score .* 0.1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove a column \n",
    "select!(df, Not(:Bonus));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filtering & Sorting Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter using Base Julia\n",
    "df_filtered = filter(row -> row.Age >= 25, df); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(df_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by Score\n",
    "df_sorted_by_score = sort(df, :Score);                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(df_sorted_by_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**\n",
    "- Use `filter` and `sort` for row-wise operations.\n",
    "\n",
    "- Use `select!`, `transform`, and `combine` for column operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Mock (or Real World) Example\n",
    "\n",
    "**Scenario:** Analyze employee data to calculate average salary by age group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mock student dataset\n",
    "students = DataFrame(\n",
    "    ID = 1:8,\n",
    "    Name = [\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eve\", \"Frank\", \"Grace\", \"Heidi\"],\n",
    "    Age = [14, 15, 16, 14, 15, 16, 14, 15],\n",
    "    Score = [85, 92, 78, 88, 95, 81, 90, 87],\n",
    "    Active = [true, true, false, true, true, false, true, true],\n",
    "    Grade = [9, 10, 9, 10, 11, 11, 12, 12],\n",
    "    Attendance = [95, 88, 92, 85, 90, 78, 96, 89],\n",
    "    Scholarship = [false, true, false, true, false, true, false, true]\n",
    ");\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "CSV.write(\"students.csv\", students);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the dataset\n",
    "students = CSV.read(\"students.csv\", DataFrame)\n",
    "println(\"Student Dataset:\")\n",
    "println(students)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis Tasks**\n",
    "\n",
    "- Task 1: Calculate the average score by grade.\n",
    "- Task 2: Identify top-performing students (score ≥ 90).\n",
    "- Task 3: Calculate the average attendance for scholarship vs. non-scholarship students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: Average score by grade\n",
    "avg_score_by_grade = combine(\n",
    "    groupby(students, :Grade),\n",
    "    :Score => mean => :Average_Score\n",
    ");\n",
    "\n",
    "# Display results\n",
    "println(\"\\nAverage Score by Grade:\")\n",
    "println(avg_score_by_grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: Top-performing students (score ≥ 90)\n",
    "top_students = filter(row -> row.Score >= 90, students)\n",
    "\n",
    "println(\"\\nTop-Performing Students (Score ≥ 90):\")\n",
    "println(top_students)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3: Average attendance for scholarship vs. non-scholarship students\n",
    "avg_attendance_by_scholarship = combine(\n",
    "    groupby(students, :Scholarship),\n",
    "    :Attendance => mean => :Average_Attendance\n",
    ")\n",
    "\n",
    "println(\"\\nAverage Attendance by Scholarship Status:\")\n",
    "println(avg_attendance_by_scholarship)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE:\n",
    "\n",
    "- Task 1: Use groupby + combine for grouped calculations.\n",
    "- Task 2: Use filter to subset rows based on conditions.\n",
    "- Task 3: Compare groups (e.g., scholarship vs. non-scholarship) using groupby."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Introduction to [DataFramesMeta.jl](https://juliadata.org/DataFramesMeta.jl/stable/)\n",
    "\n",
    "1. What is DataFramesMeta.jl?\n",
    "2. Key Features of DataFramesMeta.jl\n",
    "3. Basic Operations\n",
    "4. Mock (or Real) World Example\n",
    "\n",
    "_**Goal:** Show how DataFramesMeta.jl simplifies and streamlines data manipulation with a chainable, expressive syntax._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. What is DataFramesMeta.jl?\n",
    "\n",
    "- **Definition:** A meta-package built on DataFrames.jl that provides a concise, chainable syntax for data manipulation.\n",
    "\n",
    "- **Inspiration:** Borrows ideas from R’s `dplyr` and Python’s `pandas`.\n",
    "\n",
    "- **Why Use It?:** Reduces boilerplate code, improves readability, and makes workflows more intuitive.\n",
    "\n",
    "**Key:**\n",
    "- DataFramesMeta.jl is not a replacement for DataFrames.jl—it’s a **syntactic sugar*** layer on top."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It is an example of _**metaprogramming tools for DataFrames.jl objects to provide more convenient syntax.**_\n",
    "\n",
    "DataFrames.jl has the functions select, transform, and combine, as well as the in-place select! and transform! for manipulating data frames. \n",
    "\n",
    "DataFramesMeta.jl provides the macros @select, @transform, @combine, @select!, and @transform! to mirror these functions with more convenient syntax. Inspired by dplyr in R and LINQ in C#.\n",
    "\n",
    "In addition, DataFramesMeta provides\n",
    "\n",
    "- @orderby, for sorting data frames\n",
    "- @subset and @subset!, for keeping rows of a data frame matching a given condition\n",
    "- Row-wise versions of the above macros in the form of @rtransform, @rtransform!, @rselect, @rselect!, @rorderby, @rsubset, and @rsubset!.\n",
    "- @rename and @rename! for renaming columns\n",
    "- @groupby for grouping data\n",
    "- @by, for grouping and combining a data frame in a single step\n",
    "- @with, for working with the columns of a data frame with high performance and convenient syntax\n",
    "- @eachrow and @eachrow! for looping through rows in data frame, again with high performance and convenient syntax.\n",
    "- @byrow for applying functions to each row of a data frame (only supported inside other macros).\n",
    "- @passmissing for propagating missing values inside row-wise DataFramesMeta.jl transformations.\n",
    "- @astable to create multiple columns within a single transformation.\n",
    "- @chain, from Chain.jl for piping the above macros together, similar to magrittr's %>% in R.\n",
    "- @label! and @note! for attaching metadata to columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Coverage:**\n",
    "\n",
    "1. Chainable Syntax: Use @chain to create readable, step-by-step workflows.\n",
    "\n",
    "2. Symbol-Based Operations: Refer to columns using symbols (:column_name).\n",
    "\n",
    "3. Common Verbs:\n",
    "    - @select: Select or rename columns.\n",
    "    - @transform: Add or modify columns.\n",
    "    - @subset: Filter rows based on conditions.\n",
    "    - @groupby: Group data by one or more columns.\n",
    "    - @combine: Summarize grouped data.\n",
    "    - @orderby: Sort rows by one or more columns.\n",
    "\n",
    "**Key Point:**\n",
    "\n",
    "- DataFramesMeta.jl is ideal for users familiar with dplyr or pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the dataset\n",
    "students = CSV.read(\"students.csv\", DataFrame)\n",
    "println(\"Student Dataset:\")\n",
    "println(students)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select specific columns\n",
    "selected = @chain students begin\n",
    "    @select(:Name, :Score, :Grade)\n",
    "end\n",
    "\n",
    "# Rename columns\n",
    "renamed = @chain students begin\n",
    "    @select(:Student_Name = :Name, :Exam_Score = :Score)\n",
    "end\n",
    "\n",
    "println(\"Selected Columns:\")\n",
    "println(selected)\n",
    "\n",
    "println(\"\\nRenamed Columns:\")\n",
    "println(renamed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @transform: Add or Modify Columns\n",
    "\n",
    "# Add a new column for pass/fail status\n",
    "transformed = @chain students begin\n",
    "    @transform(:Pass = :Score .>= 90)\n",
    "end\n",
    "\n",
    "println(\"Transformed DataFrame:\")\n",
    "println(transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @subset: Filter Rows Based on Conditions\n",
    "\n",
    "# Filter active students with a score ≥ 90\n",
    "filtered = @chain students begin\n",
    "    @subset(:Active .&& :Score .>= 90)\n",
    "end\n",
    "\n",
    "println(\"Filtered DataFrame:\")\n",
    "println(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @groupby: Group Data by One or More Columns\n",
    "\n",
    "# Group by Grade\n",
    "grouped = @chain students begin\n",
    "    @groupby(:Grade)\n",
    "end\n",
    "\n",
    "println(\"Grouped DataFrame:\")\n",
    "println(grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @combine: Summarize Grouped Data\n",
    "\n",
    "# Calculate average score by grade\n",
    "combined = @chain students begin\n",
    "    @groupby(:Grade)\n",
    "    @combine(:Average_Score = mean(:Score))\n",
    "end\n",
    "\n",
    "println(\"Combined DataFrame:\")\n",
    "println(combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @orderby: Sort Rows by One or More Columns\n",
    "\n",
    "# Sort by Score in descending order\n",
    "sorted = @chain students begin\n",
    "    @orderby(-:Score)\n",
    "end\n",
    "\n",
    "println(\"Sorted DataFrame:\")\n",
    "println(sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @orderby: Sort Rows by One or More Columns\n",
    "# Sort by Score in descending order\n",
    "sorted = @chain students begin\n",
    "    @orderby(+:Score)\n",
    "end\n",
    "\n",
    "println(\"Sorted DataFrame:\")\n",
    "println(sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's revisit the 3 tasks from before using DataFramesMeta.jl!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1: Average score by grade\n",
    "avg_score_by_grade = @chain students begin\n",
    "    @groupby(:Grade)\n",
    "    @combine(:Average_Score = mean(:Score))\n",
    "end\n",
    "\n",
    "println(avg_score_by_grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 2: Top-performing students (score ≥ 90)\n",
    "top_students = @chain students begin\n",
    "    @subset!(:Score .>= 90)  # Correct usage of @subset\n",
    "end\n",
    "\n",
    "println(top_students)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3: Average attendance for scholarship vs. non-scholarship students\n",
    "avg_attendance_by_scholarship = @chain students begin\n",
    "    @groupby(:Scholarship)\n",
    "    @combine(:Average_Attendance = mean(:Attendance))\n",
    "end\n",
    "\n",
    "println(avg_attendance_by_scholarship)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Introduction to [Arrow.jl](https://arrow.apache.org/julia/stable/)\n",
    "\n",
    "1. What is Apache Arrow?\n",
    "2. Why use Arrow?\n",
    "3. Arrow.jl in Julia\n",
    "4. Mock (or Real) World Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 What is Arrow i.e. Apache Arrow?\n",
    "\n",
    "_**Motivation:** Who here has struggled with slow CSV files? If you have, then try Arrow!_\n",
    "\n",
    "**Definition:** Arrow.jl is a Julia package that provides an interface to the Apache Arrow format, a cross-language development platform for in-memory data. Arrow is designed for high-performance data interchange and storage, making it ideal for working with large datasets and sharing data between different programming languages (e.g., Julia, Python, R, C++).\n",
    "\n",
    "- **Key Features:**\n",
    "- **Columnar Format:** Optimized for columnar operations (e.g., analytics, machine learning).\n",
    "- **Zero-Copy Reads:** No data copying between systems (e.g., Python ↔ Julia).\n",
    "- **Language Interoperability:** Works seamlessly with Python, R, C++, and more.\n",
    "\n",
    "**Key Point:**\n",
    "- Arrow is ideal for big data workflows and multi-language environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Why Use Arrow.jl?\n",
    "\n",
    "- **Performance:** Arrow is faster than CSV/JSON for reading and writing large datasets.\n",
    "- **Memory Efficiency:** Columnar format reduces memory usage.\n",
    "- **Interoperability:** Share data between Julia and other languages (e.g., Python, R).\n",
    "- **Integration:** Works seamlessly with DataFrames.jl and other Julia data tools.\n",
    "\n",
    "**Key Point:**\n",
    "- Arrow.jl is the Julia interface to Apache Arrow, enabling high-performance data workflows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CSV vs. Arrow:**\n",
    "\n",
    "- Arrow is 10–100x faster for reading/writing large datasets.\n",
    "- Arrow uses less memory due to its columnar format.\n",
    "\n",
    "**Example Benchmark:**\n",
    "\n",
    "- Load a 1GB CSV file vs. a 1GB Arrow file.\n",
    "\n",
    "**Key Point:**\n",
    "\n",
    "- Arrow is the best choice for big data workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Mock (or Real-World) Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the dataset\n",
    "students = CSV.read(\"students.csv\", DataFrame)\n",
    "\n",
    "# Save the DataFrame to an Arrow file\n",
    "Arrow.write(\"students_FROMcsv_TO.arrow\", students)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Arrow file back into Julia\n",
    "\n",
    "arrow_table = Arrow.Table(\"students_FROMcsv_TO.arrow\")\n",
    "loaded_df = DataFrame(arrow_table)\n",
    "println(loaded_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV vs Arrow Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a large dataset (1 million rows)\n",
    "# n = 1_000_000_000 # trillion is too much for a demo :-)\n",
    "n = 1_000_000\n",
    "large_df = DataFrame(\n",
    "    ID = 1:n,\n",
    "    Name = rand([\"Alice\", \"Bob\", \"Charlie\", \"David\", \"Eve\"], n),\n",
    "    Age = rand(14:18, n),\n",
    "    Score = rand(50:100, n),\n",
    "    Active = rand([true, false], n),\n",
    "    Grade = rand(9:12, n),\n",
    "    Attendance = rand(70:100, n),\n",
    "    Scholarship = rand([true, false], n)\n",
    ")\n",
    "\n",
    "# Save the dataset as CSV and Arrow\n",
    "CSV.write(\"large_data.csv\", large_df);\n",
    "Arrow.write(\"large_data.arrow\", large_df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Local Machine\n",
    "# Benchmarking Read Performance:\n",
    "#   507.539 ms (821 allocations: 68.71 MiB)\n",
    "#   187.712 μs (578 allocations: 28.24 KiB)\n",
    "###\n",
    "\n",
    "### Remote Machine Arwen\n",
    "# Benchmarking Read Performance:\n",
    "#   442.207 ms (820 allocations: 68.26 MiB)\n",
    "#   157.131 μs (513 allocations: 28.38 KiB)\n",
    "###\n",
    "\n",
    "# Benchmark reading\n",
    "println(\"Benchmarking Read Performance:\")\n",
    "@btime CSV.read(\"large_data.csv\", DataFrame)\n",
    "@btime Arrow.Table(\"large_data.arrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Local Machine\n",
    "# Benchmarking Write Performance:\n",
    "# 1.085 s (33994424 allocations: 888.93 MiB)\n",
    "# 69.193 ms (324 allocations: 27.04 MiB)\n",
    "###\n",
    "\n",
    "### Remote Machine Arwen\n",
    "# Benchmarking Write Performance:\n",
    "#   765.590 ms (33994399 allocations: 888.93 MiB)\n",
    "#   471.580 ms (407 allocations: 19.83 MiB)\n",
    "###\n",
    "\n",
    "# Benchmark writing\n",
    "println(\"\\nBenchmarking Write Performance:\")\n",
    "@btime CSV.write(\"large_data.csv\", large_df)\n",
    "@btime Arrow.write(\"large_data.arrow\", large_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![CSV_vs_Arrow](./img/CSV_vs_Arrow.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots\n",
    "\n",
    "###\n",
    "# Plot takes about 1 minutes\n",
    "###\n",
    "\n",
    "###\n",
    "# Benchmarking Read Performance:\n",
    "#   507.539 ms (821 allocations: 68.71 MiB)  --> 0.507539000 s\n",
    "#   187.712 μs (578 allocations: 28.24 KiB)  --> 0.000187712 s\n",
    "###\n",
    "\n",
    "###\n",
    "# Benchmarking Write Performance:\n",
    "# 1.085 s (33994424 allocations: 888.93 MiB) --> 1.085000000 s\n",
    "# 69.193 ms (324 allocations: 27.04 MiB)     --> 0.069193000 s\n",
    "###\n",
    "\n",
    "\n",
    "# Data for plotting\n",
    "\n",
    "using Plots\n",
    "\n",
    "# Data for plotting\n",
    "operations = [\"Read\", \"Write\"]\n",
    "csv_times = [0.507539000, 1.085000000]  # Replace with actual benchmark results\n",
    "arrow_times = [0.000187712, 0.069193000]  # Replace with actual benchmark results\n",
    "\n",
    "# Plot \n",
    "bar(operations, [csv_times arrow_times],\n",
    "    label = [\"CSV\", \"Arrow\"],\n",
    "    xlabel = \"Operation\",\n",
    "    ylabel = \"Time (seconds)\",\n",
    "    title = \"CSV vs Arrow Performance\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Introduction to [Big Data Analysis in Julia](...)\n",
    "\n",
    "1. Challenges of Big Data\n",
    "2. Julia’s Approach to Big Data \n",
    "3. Distributed Computing via [Distributed.jl](https://docs.julialang.org/en/v1/stdlib/Distributed/)\n",
    "4. Out-of-Core Computing via [Dagger.jl](https://juliaparallel.org/Dagger.jl/stable/)\n",
    "5. Handing Large Datasets via [CSV.jl](https://csv.juliadata.org/stable/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1. Challenges of Big Data\n",
    "\n",
    "_**Goal:** Demonstrate how Julia handles large datasets using distributed and out-of-core computing._\n",
    "\n",
    "- **Volume:** Datasets too large to fit into memory.\n",
    "- **Velocity:** Data arriving in real-time streams.\n",
    "- **Variety:** Structured, semi-structured, and unstructured data.\n",
    "- **Julia’s Solution:** Distributed and out-of-core computing.\n",
    "\n",
    "**Key Point:**\n",
    "\n",
    "- Julia provides tools to handle big data efficiently, even on a single machine or a cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2. Julia’s Approach to Big Data\n",
    "\n",
    "Distributed Parallel Computing:\n",
    "- Use multiple processes or machines to parallelize computations.\n",
    "- Tools: Distributed.jl, MPI.jl.\n",
    "\n",
    "Out-of-Core Parallel Computing:\n",
    "- Process data that doesn’t fit into memory by working in chunks.\n",
    "- Tools: Dagger.jl, CSV.jl (with chunking).\n",
    "\n",
    "Integration:\n",
    "- Works seamlessly with DataFrames.jl, CSV.jl, Arrow.jl, and other data tools.\n",
    "\n",
    "**Key Point:**\n",
    "\n",
    "- Julia’s ecosystem is designed for scalability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Distributed\n",
    "\n",
    "# nprocs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Worker Processes: Add one Julia worker per CPU core\n",
    "# addprocs()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel Map-Reduce:\n",
    "# @btime @distributed (+) for i in 1:1_000_000\n",
    "#     i^2\n",
    "# end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:**\n",
    "\n",
    "`Distributed.jl` makes it easy to parallelize computations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Out-of-Core Computing with Dagger.jl\n",
    "\n",
    "**What is Dagger.jl?**\n",
    "- A framework for out-of-core and parallel computation.\n",
    "- Works with large datasets by processing them in chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a large distributed array\n",
    "# arr = Dagger.ones(10^6);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the sum in chunks\n",
    "# sum_arr = sum(arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Integration with DataFrames**\n",
    "\n",
    "- Use Dagger to process large DataFrames in chunks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Point**\n",
    "\n",
    "- Dagger.jl enables you to work with datasets larger than memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3. Mock (or Real) World Example\n",
    "\n",
    "_**Scenario:** Analyze a 10GB dataset of student records._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**\n",
    "\n",
    "1. Distributed Computing: Use Distributed.jl to parallelize computations.\n",
    "\n",
    "2. Out-of-Core Computing: Use Dagger.jl to process large datasets in chunks.\n",
    "\n",
    "3. Integration: Julia’s tools work seamlessly together for big data workflows.\n",
    "\n",
    "**Key Point**\n",
    "\n",
    "- Julia is a powerful tool for big data analysis, from small datasets to terabytes of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Distributed, Dagger, CSV, DataFrames\n",
    "\n",
    "# # Step 1: Add worker processes\n",
    "# addprocs(4)\n",
    "\n",
    "# # Step 2: Read the dataset in chunks\n",
    "# df = CSV.read(\"large_students.csv\", DataFrame; chunksize=100_000)\n",
    "\n",
    "# # Step 3: Process chunks in parallel\n",
    "# @distributed for chunk in df\n",
    "#     # Perform analysis on each chunk\n",
    "# end\n",
    "\n",
    "# # Step 4: Combine results\n",
    "# results = fetch(@distributed (+) for chunk in df\n",
    "#     sum(chunk.Score)\n",
    "# end)\n",
    "\n",
    "# println(\"Total Score: \", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fin!\n",
    "\n",
    "**A Data Project's Logical Flow in Julia and Elsewhere**:  \n",
    "   - Start simple (DataFrames & DataFramesMeta) → Build complexity (CSV & Arrow) → Scale up to Big Data (Distributed & Dagger). \n",
    "\n",
    "## References\n",
    "\n",
    "1. [JuliaData](https://github.com/JuliaData): Data manipulation, storage, and I/O in Julia \n",
    "2. [Julia Data Science](https://juliadatascience.io): Data Science using Julia\n",
    "3. [Julia for Data Analysis](https://github.com/bkamins/JuliaForDataAnalysis)\n",
    "4. [Wikipedia on Data](https://en.wikipedia.org/wiki/Data)\n",
    "5. [Wikipedia on Data Literacy](https://en.wikipedia.org/wiki/Data_literacy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.4",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
